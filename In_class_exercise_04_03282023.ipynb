{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreelakshmi0702/SreeLakshmi_INFO5731_Fall2023/blob/main/In_class_exercise_04_03282023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WfPsNPAY__3"
      },
      "source": [
        "# **The fourth in-class-exercise (40 points in total, 03/28/2022)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8pomWAfY__8"
      },
      "source": [
        "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J3J7xqzY__9"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evJvA-vAY__-",
        "outputId": "55792075-70e0-4f05-ae64-44b106275a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk; nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "!pip install pyLDAvis\n",
        "\n",
        "!pip install --upgrade pyLDAvis gensim pandas numpy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh7x4-FabDuQ",
        "outputId": "f7634a43-d993-4f58-c8ae-fef33da19de0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.3)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.7)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.2.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.7)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "lAzZoTxca46B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5zDW7xmbSwf",
        "outputId": "f5cb3dcf-1a0c-4319-c6be-10a45f202d1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Tweets.csv\")\n",
        "\n",
        "#Cleaning the data\n",
        "import re\n",
        "\n",
        "def cleantext(tweets):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', tweets) #removes @mentions\n",
        "    text = re.sub(r'#[A-Za-z0-9_]+', '', text) #removing Hashtag symbols.\n",
        "    text = re.sub(r'RT[\\s]+', '', text) #removing Retweet symbol (RT).\n",
        "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #remove URL's.\n",
        "    text = re.sub(r\"www.\\S+\", \"\", text)\n",
        "    text = re.sub('[()!?]', ' ', text)\n",
        "    text = re.sub('\\[.*?\\]',' ', text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]\",\" \", text)#Filtering non-alphanumeric characters\n",
        "    text = re.sub('\\\\n', '', text)#removing the '\\n' character\n",
        "    text = re.sub(r'[0-9]+', '', text)#removing numbers\n",
        "\n",
        "    return text\n",
        "\n",
        "df[\"Text\"] = df[\"Text\"].apply(cleantext)\n",
        "\n",
        "# Convert to list\n",
        "data = df.Text.values.tolist()"
      ],
      "metadata": {
        "id": "lng-LkZtbenV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting sentences to words\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))"
      ],
      "metadata": {
        "id": "hk7lC8Qehtk7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AKh-41AhvAx",
        "outputId": "a54b9552-8ea8-4405-9693-d0f11d115e00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['optimistic', 'about', 'our', 'ability', 'to', 'prevent', 'the', 'next', 'pandemic', 'we', 'have', 'learned', 'so', 'much', 'from', 'covid', 'and', 'the', 'innovations', 'have', 'been', 'tremendous']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "metadata": {
        "id": "wkE4a1BChz9e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R3874EEh4I9",
        "outputId": "68746cc9-5b97-4358-f96e-23b812424b38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['optimistic', 'ability', 'prevent', 'next', 'pandemic', 'learn', 'much', 'covid', 'innovation', 'tremendous']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITHFy3wsh8I7",
        "outputId": "10fab787-1422-4044-f815-6ae9755e617d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see what word a given id corresponds to, pass the id as a key to the dictionary\n",
        "id2word[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JcWtWrpGh-zT",
        "outputId": "b6bb1edc-9dae-4c65-a0d8-e79725bc2bc7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ability'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or, you can see a human-readable form of the corpus itself.\n",
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5pwWcNKiB7S",
        "outputId": "61498644-a94a-4e86-d0a4-798a10df0dee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('ability', 1),\n",
              "  ('covid', 1),\n",
              "  ('innovation', 1),\n",
              "  ('learn', 1),\n",
              "  ('much', 1),\n",
              "  ('next', 1),\n",
              "  ('optimistic', 1),\n",
              "  ('pandemic', 1),\n",
              "  ('prevent', 1),\n",
              "  ('tremendous', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10,\n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "metadata": {
        "id": "1E4y5yjNiFGC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtXgCj5YiKeM",
        "outputId": "48306133-904a-44b3-e08c-e1fe94d7425a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.041*\"young\" + 0.026*\"opportunity\" + 0.026*\"ask\" + 0.021*\"million\" + '\n",
            "  '0.021*\"community\" + 0.021*\"power\" + 0.020*\"life\" + 0.019*\"generation\" + '\n",
            "  '0.019*\"question\" + 0.018*\"worker\"'),\n",
            " (1,\n",
            "  '0.102*\"book\" + 0.062*\"read\" + 0.029*\"keep\" + 0.021*\"conversation\" + '\n",
            "  '0.021*\"late\" + 0.016*\"tackle\" + 0.016*\"thank\" + 0.015*\"author\" + '\n",
            "  '0.014*\"partnership\" + 0.014*\"favorite\"'),\n",
            " (2,\n",
            "  '0.039*\"new\" + 0.031*\"good\" + 0.030*\"work\" + 0.026*\"need\" + 0.024*\"get\" + '\n",
            "  '0.020*\"investment\" + 0.019*\"learn\" + 0.019*\"help\" + 0.019*\"global\" + '\n",
            "  '0.018*\"important\"'),\n",
            " (3,\n",
            "  '0.031*\"life\" + 0.029*\"help\" + 0.028*\"great\" + 0.025*\"way\" + '\n",
            "  '0.020*\"pandemic\" + 0.017*\"take\" + 0.017*\"covid\" + 0.016*\"thing\" + '\n",
            "  '0.015*\"even\" + 0.014*\"well\"'),\n",
            " (4,\n",
            "  '0.035*\"inspire\" + 0.027*\"work\" + 0.023*\"year\" + 0.022*\"live\" + '\n",
            "  '0.021*\"change\" + 0.017*\"government\" + 0.016*\"save\" + 0.016*\"meet\" + '\n",
            "  '0.015*\"team\" + 0.014*\"never\"'),\n",
            " (5,\n",
            "  '0.075*\"world\" + 0.047*\"people\" + 0.038*\"make\" + 0.031*\"year\" + '\n",
            "  '0.027*\"progress\" + 0.023*\"health\" + 0.020*\"country\" + 0.020*\"day\" + '\n",
            "  '0.019*\"see\" + 0.018*\"time\"'),\n",
            " (6,\n",
            "  '0.074*\"climate_change\" + 0.031*\"innovation\" + 0.028*\"leadership\" + '\n",
            "  '0.027*\"reach\" + 0.027*\"partner\" + 0.024*\"emission\" + 0.021*\"excited\" + '\n",
            "  '0.020*\"join\" + 0.020*\"poor\" + 0.020*\"energy\"'),\n",
            " (7,\n",
            "  '0.072*\"vaccine\" + 0.031*\"diagnostic\" + 0.030*\"say\" + 0.021*\"test\" + '\n",
            "  '0.017*\"soon\" + 0.016*\"receive\" + 0.016*\"reliable\" + 0.016*\"exciting\" + '\n",
            "  '0.015*\"treatment\" + 0.013*\"blood\"'),\n",
            " (8,\n",
            "  '0.036*\"talk\" + 0.026*\"leader\" + 0.023*\"child\" + 0.021*\"fight\" + '\n",
            "  '0.019*\"polio\" + 0.019*\"year\" + 0.017*\"love\" + 0.017*\"learn\" + '\n",
            "  '0.016*\"impact\" + 0.015*\"student\"'),\n",
            " (9,\n",
            "  '0.042*\"disease\" + 0.040*\"fight\" + 0.033*\"ever\" + 0.031*\"alzheimer\" + '\n",
            "  '0.024*\"commitment\" + 0.020*\"stop\" + 0.018*\"breakthrough\" + 0.017*\"big\" + '\n",
            "  '0.013*\"toilet\" + 0.012*\"carbon\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCQX1QMhiObC",
        "outputId": "55e220ae-b4c0-4755-ba6b-6c51dba1d6d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -7.412594668358864\n",
            "\n",
            "Coherence Score:  0.3761221366588604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "#pyLDAvis.enable_notebook()\n",
        "#vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "#vis\n",
        "import pyLDAvis.gensim\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "# Replace these with your actual lda_model, corpus, and id2word\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=10,\n",
        "    random_state=100,\n",
        "    update_every=1,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "x9MK2ZWRiRfq",
        "outputId": "359bf331-9274-4a98-a9b1-4ce6aa21612b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.171877  0.262794       1        1  19.133237\n",
              "2      0.205056 -0.196207       2        1  17.208883\n",
              "3      0.177264  0.005745       3        1  14.266146\n",
              "4     -0.176659  0.026600       4        1   9.396375\n",
              "8     -0.040275  0.132458       5        1   9.064282\n",
              "6     -0.006168 -0.180057       6        1   8.672335\n",
              "9     -0.049672 -0.016599       7        1   7.867071\n",
              "0     -0.073140 -0.048051       8        1   6.811593\n",
              "1     -0.114332  0.005775       9        1   4.562496\n",
              "7     -0.093951  0.007541      10        1   3.017581, topic_info=               Term        Freq       Total Category  logprob  loglift\n",
              "65            world  194.000000  194.000000  Default  30.0000  30.0000\n",
              "204  climate_change   82.000000   82.000000  Default  29.0000  29.0000\n",
              "414            book   59.000000   59.000000  Default  28.0000  28.0000\n",
              "33           people  121.000000  121.000000  Default  27.0000  27.0000\n",
              "23             year  126.000000  126.000000  Default  26.0000  26.0000\n",
              "..              ...         ...         ...      ...      ...      ...\n",
              "869          course    2.035120    2.815844  Topic10  -5.2350   3.1760\n",
              "767      administer    1.991060    2.771741  Topic10  -5.2569   3.1699\n",
              "296         develop    4.873399   22.828075  Topic10  -4.3618   1.9565\n",
              "78          country    4.845332   67.630710  Topic10  -4.3676   0.8647\n",
              "60             live    3.549764   30.057659  Topic10  -4.6787   1.3645\n",
              "\n",
              "[421 rows x 6 columns], token_table=      Topic      Freq         Term\n",
              "term                              \n",
              "0         9  0.895111      ability\n",
              "119       2  0.306676   accelerate\n",
              "119       6  0.690020   accelerate\n",
              "850      10  0.853210  accelerator\n",
              "366       9  0.826917       access\n",
              "...     ...       ...          ...\n",
              "23        1  0.602440         year\n",
              "23        4  0.221952         year\n",
              "23        5  0.174390         year\n",
              "2155      6  0.846053        yield\n",
              "175       8  0.988075        young\n",
              "\n",
              "[457 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 3, 4, 5, 9, 7, 10, 1, 2, 8])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el139331323767259115042788611779\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el139331323767259115042788611779_data = {\"mdsDat\": {\"x\": [0.17187685766998292, 0.20505605163464394, 0.1772642864916327, -0.17665928974277065, -0.0402751628325834, -0.006168311393460406, -0.04967178920686565, -0.07314005849403515, -0.11433194475753851, -0.09395063936900544], \"y\": [0.2627940870262803, -0.19620728541596907, 0.00574517325262328, 0.0266004535028799, 0.13245841019845725, -0.1800571521143574, -0.01659859988165269, -0.04805064147257125, 0.005774703075671541, 0.00754085182863894], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [19.133236838679718, 17.208883304036142, 14.266145615161587, 9.39637521718212, 9.06428227599798, 8.67233539064329, 7.867070967461855, 6.811593187885146, 4.56249599543084, 3.0175812075213226]}, \"tinfo\": {\"Term\": [\"world\", \"climate_change\", \"book\", \"people\", \"year\", \"new\", \"fight\", \"good\", \"work\", \"read\", \"disease\", \"make\", \"vaccine\", \"life\", \"talk\", \"young\", \"inspire\", \"innovation\", \"health\", \"great\", \"ever\", \"energy\", \"alzheimer\", \"progress\", \"get\", \"country\", \"leadership\", \"learn\", \"thank\", \"day\", \"day\", \"improve\", \"challenge\", \"write\", \"together\", \"first\", \"continue\", \"poverty\", \"come\", \"want\", \"invest\", \"end\", \"problem\", \"idea\", \"hard\", \"put\", \"case\", \"still\", \"person\", \"insight\", \"benefit\", \"brilliant\", \"tough\", \"people\", \"mind\", \"death\", \"optimistic\", \"reason\", \"world\", \"rest\", \"find\", \"future\", \"time\", \"progress\", \"make\", \"country\", \"many\", \"thank\", \"year\", \"see\", \"health\", \"incredible\", \"story\", \"good\", \"investment\", \"important\", \"look\", \"technology\", \"possible\", \"malaria\", \"next\", \"support\", \"excite\", \"create\", \"scientist\", \"action\", \"show\", \"wait\", \"solution\", \"education\", \"african\", \"job\", \"critical\", \"ago\", \"commit\", \"explain\", \"climate\", \"beat\", \"build\", \"school\", \"grow\", \"increase\", \"ensure\", \"new\", \"give\", \"lot\", \"global\", \"get\", \"need\", \"learn\", \"work\", \"today\", \"energy\", \"tool\", \"help\", \"health\", \"make\", \"innovation\", \"take\", \"pandemic\", \"step\", \"much\", \"start\", \"know\", \"right\", \"understand\", \"easy\", \"close\", \"electricity\", \"issue\", \"report\", \"friend\", \"care\", \"early\", \"bad\", \"become\", \"home\", \"area\", \"enough\", \"part\", \"identify\", \"thought\", \"bear\", \"plan\", \"high\", \"economic\", \"source\", \"try\", \"matter\", \"thing\", \"covid\", \"even\", \"great\", \"way\", \"datum\", \"life\", \"last\", \"go\", \"help\", \"take\", \"well\", \"need\", \"share\", \"inspire\", \"change\", \"government\", \"meet\", \"team\", \"never\", \"congratulation\", \"company\", \"turn\", \"hear\", \"call\", \"remarkable\", \"kid\", \"advocate\", \"place\", \"teach\", \"amazing\", \"chance\", \"list\", \"visit\", \"low\", \"kind\", \"safe\", \"climate_disaster\", \"hero\", \"miss\", \"optimism\", \"thrill\", \"risk\", \"contribute\", \"live\", \"save\", \"work\", \"favorite\", \"use\", \"think\", \"year\", \"talk\", \"child\", \"love\", \"impact\", \"really\", \"recently\", \"science\", \"enjoy\", \"teacher\", \"watch\", \"drive\", \"free\", \"news\", \"old\", \"tomorrow\", \"agriculture\", \"fun\", \"travel\", \"interested\", \"wish\", \"epidemic\", \"century\", \"man\", \"almost\", \"project\", \"guest\", \"age\", \"catch\", \"melinda\", \"plant\", \"polio\", \"leader\", \"family\", \"student\", \"foundation\", \"fight\", \"learn\", \"story\", \"today\", \"year\", \"share\", \"always\", \"think\", \"many\", \"climate_change\", \"leadership\", \"reach\", \"partner\", \"excited\", \"join\", \"poor\", \"woman\", \"emission\", \"bring\", \"reduce\", \"nuclear\", \"sector\", \"encourage\", \"farmer\", \"worst_effect\", \"require\", \"public\", \"slow\", \"event\", \"growth\", \"everywhere\", \"speak\", \"entire\", \"entrepreneur\", \"yield\", \"equal\", \"summit\", \"catalyst\", \"promise\", \"innovation\", \"potential\", \"accelerate\", \"energy\", \"save\", \"work\", \"see\", \"effort\", \"world\", \"ever\", \"alzheimer\", \"commitment\", \"disease\", \"stop\", \"breakthrough\", \"toilet\", \"carbon\", \"solve\", \"research\", \"week\", \"goal\", \"face\", \"nearly\", \"approach\", \"female\", \"tech\", \"spread\", \"greenhouse_gas\", \"population\", \"large\", \"diagnose\", \"win\", \"key\", \"sanitation\", \"success\", \"renewable\", \"president\", \"ai\", \"trial\", \"big\", \"fight\", \"get\", \"avoid\", \"young\", \"opportunity\", \"ask\", \"million\", \"community\", \"power\", \"generation\", \"question\", \"answer\", \"check\", \"decade\", \"annual\", \"history\", \"organization\", \"researcher\", \"lesson\", \"healthy\", \"ahead\", \"human\", \"worth\", \"forward\", \"sit\", \"long\", \"series\", \"black\", \"letter\", \"guide\", \"often\", \"response\", \"provide\", \"worker\", \"effort\", \"lead\", \"life\", \"share\", \"new\", \"book\", \"read\", \"keep\", \"conversation\", \"late\", \"tackle\", \"author\", \"partnership\", \"lift\", \"tell\", \"humanity\", \"gene\", \"fascinating\", \"access\", \"innovative\", \"discuss\", \"importance\", \"blog\", \"glad\", \"hopeful\", \"thinker\", \"ability\", \"discussion\", \"recommendation\", \"stay\", \"summer\", \"piece\", \"hand\", \"software\", \"listen\", \"recommend\", \"favorite\", \"thank\", \"lot\", \"great\", \"vaccine\", \"diagnostic\", \"say\", \"test\", \"soon\", \"receive\", \"reliable\", \"exciting\", \"treatment\", \"blood\", \"accelerator\", \"candidate\", \"reality\", \"one\", \"serve\", \"stand\", \"app\", \"drug\", \"wealthy\", \"positive\", \"supply\", \"seattle\", \"forever\", \"language\", \"accessible\", \"leone\", \"begin\", \"testing\", \"course\", \"administer\", \"develop\", \"country\", \"live\"], \"Freq\": [194.0, 82.0, 59.0, 121.0, 126.0, 99.0, 63.0, 69.0, 120.0, 36.0, 43.0, 136.0, 28.0, 84.0, 41.0, 36.0, 41.0, 57.0, 93.0, 60.0, 34.0, 58.0, 31.0, 83.0, 75.0, 67.0, 31.0, 62.0, 56.0, 48.0, 47.693625538515356, 40.18385709264764, 35.42456798451211, 34.874618762871954, 33.743640411823755, 30.753144591237778, 28.63350435704977, 27.09871732628741, 26.83996400879276, 24.404818491379764, 24.384051174959662, 29.17562043120371, 21.101874390692018, 20.48159153630914, 17.823592747304257, 16.383317875093883, 15.080452473158676, 14.375527857761885, 13.878869758463859, 13.720753886221964, 13.371844921637273, 12.786915011122188, 11.797176972639367, 114.0423701067141, 11.517359662775753, 11.3527214318407, 34.404514853064924, 10.901211094904536, 181.7449767547796, 10.365537288218016, 22.742914276872224, 28.887966589717582, 43.08431458286861, 64.50175968342073, 91.77666642587631, 47.74131478723759, 31.338442244563993, 40.375958717692626, 75.91045472964304, 44.81578310313362, 55.65003229309444, 21.601077360486716, 21.621494982822615, 68.52427210259961, 43.81052934172844, 38.73682961017745, 36.11750976218745, 35.671751411885126, 32.09704232674784, 31.637477427580116, 34.71500871087934, 29.5513289975032, 26.309898719729127, 23.70219187573041, 21.352276269379793, 20.913100582881015, 19.162053164882344, 18.24535432562108, 17.028072875626254, 16.248509145440057, 16.25074936148171, 16.123688122459882, 16.004105430740143, 15.283711609672189, 15.233451835190623, 15.092377070821291, 14.698934055553238, 14.597443543387273, 18.933165584206424, 13.786533022067532, 13.768292712286366, 13.724249334402264, 12.631278568316532, 84.99337455057224, 23.598652905145926, 33.740934773268705, 40.4517433985985, 51.72882861777682, 56.73847521565864, 41.57423773651214, 65.73337686766595, 32.015804057520015, 36.725225180558965, 19.88193563228862, 41.52748946009224, 37.36205123238477, 38.18152388376588, 22.811671503093553, 22.059316048989317, 35.69433504527978, 25.64476629208448, 24.579425896354525, 24.449850240980524, 22.44333686721446, 20.952739088733463, 19.460896490382073, 17.574311417994448, 22.386642050874038, 17.102415344828955, 16.15060420346801, 15.441945073142469, 15.032824929603176, 14.428458153770508, 14.129142898123126, 13.926590518941744, 13.006066411053057, 12.796582572039295, 12.653694913902635, 12.394462016987452, 11.666898446522051, 10.914334182929885, 10.577524616348411, 10.158928702092993, 10.135214042467467, 10.075705765001054, 9.982171009253006, 9.826217789044245, 9.779199765007128, 9.77097386072844, 28.720820487548572, 30.586435391687086, 27.982487543015242, 49.80862421440887, 44.99254398221697, 22.792688835084665, 55.10336796616977, 24.24244979306066, 25.223778305051088, 51.79906090776769, 31.27879074608849, 25.90971274398587, 17.50162234850847, 14.574628603768081, 41.126496684135404, 24.512146507845777, 20.717203162927838, 18.91058734875211, 17.274182509588023, 16.635422681456436, 16.620958116813043, 15.085087264783981, 14.953325108022444, 14.487293565578089, 14.051377789627194, 13.138185671035407, 12.764999903235804, 11.846034146470386, 11.547399332067606, 11.10035398492997, 10.824382722406213, 10.166764115661437, 9.919158025059208, 9.555983885457056, 9.211594844380103, 9.059296994521437, 8.635178896419863, 8.635125713799956, 8.597472972891582, 8.584813847396896, 8.569391441609556, 8.56797600834016, 8.04304748427717, 7.713739039857532, 25.809181969672238, 19.484662707450827, 32.41177099196123, 13.477409904139538, 16.163480112403693, 16.244591363560264, 27.65485155439951, 40.77340048330506, 26.548039297439118, 19.992541396553463, 17.952515904259737, 17.18392956331231, 15.407699844338842, 15.266163405729044, 15.048220761394463, 13.38342971845564, 13.001289670947397, 12.230422483929823, 10.98316201102724, 10.900101378108106, 10.602000995852762, 8.114909900777041, 7.840967889526177, 7.055424302409147, 6.892276473200287, 6.550813829703636, 6.541430189557026, 6.521637917988608, 6.467138629544421, 6.076595577442221, 5.835335717612629, 5.726386840509758, 5.57834347084323, 5.510428446751199, 5.469021578145944, 5.419169486849371, 5.381685694861023, 22.091541830018063, 30.17603172122363, 15.83132157733374, 17.410400263314052, 14.330939562461683, 23.62542684438162, 18.965190183153727, 13.09510362734908, 14.647924794395307, 21.91378333268412, 12.107645843925106, 8.06962484568372, 9.81344496044674, 8.579211175408712, 81.58147073258547, 30.867414104466995, 29.632651603280703, 29.218855976668845, 22.935615443682696, 22.449473176027332, 21.91616672311997, 21.211812637006513, 25.82457671370287, 17.944059210761193, 15.185018797084338, 13.920598958820761, 13.083810474727686, 13.056072550852734, 12.609214341578205, 11.872459292589989, 10.651635801185797, 9.898097902183363, 8.872814247293245, 8.53596132066889, 7.332825676979537, 7.162108342369263, 7.122727137342599, 7.080602306518461, 6.373095556098774, 6.32849962138362, 5.856931395795199, 5.583797976766566, 5.38189145586372, 5.133554973832089, 33.5563903119792, 10.313419242432879, 8.742453674553015, 21.454871499678934, 11.800296718875426, 18.189995659342703, 10.903409229287243, 7.778053867796678, 7.9780731872797555, 33.25167848201039, 30.67423525497389, 24.05914482503558, 42.29073905177152, 20.06962934406487, 18.198154526004092, 12.826155842759283, 12.424138246646818, 12.084278345475484, 12.035586326738954, 11.362928676018331, 11.216950022399091, 10.927653197342673, 10.05943897451598, 9.233172800598902, 8.865023476615809, 8.813961328180826, 8.719614396239171, 8.38686766709435, 8.217228532814149, 7.88268403014463, 7.7696923871230466, 7.740055561811483, 7.622582008168342, 7.278361253880596, 7.095510617774416, 7.029328340564503, 6.933163226936364, 6.9267249157144, 6.875734195845673, 17.345373511707017, 39.43959640114623, 12.092763502560318, 8.905795273291517, 35.667756059539784, 22.742912329941333, 22.16000395333311, 18.14156945288616, 17.97745900740938, 17.891081030527786, 16.127602956053845, 15.99205867071404, 14.212725678591111, 13.486615428757297, 11.582602062952121, 11.504229454064827, 11.431101658361316, 11.412338399435379, 11.046094620867688, 9.899646729814629, 9.286845327620792, 9.277512290990538, 8.354629983410641, 8.172727332474878, 7.525497305913067, 7.501237836172945, 6.610072994170539, 6.132458860553843, 5.906388939024474, 5.861384345652293, 5.42998119275878, 5.3734733506242485, 5.35854410635877, 5.22399336373081, 15.70402927313208, 13.738454812183832, 12.363753936472229, 17.66150921229378, 9.321216122501902, 8.085456211296139, 58.70558916355324, 35.82586506993243, 16.714188759068914, 12.327836299789656, 11.971263760460058, 9.030633497691857, 8.466838058241871, 8.271332484079851, 8.023639618614272, 7.528928521601932, 6.7974198431143185, 6.719884285181723, 6.526135233942296, 6.476586761914486, 6.2753161342644095, 6.229276942182716, 5.974263706913855, 5.947410694614224, 5.821769541982577, 5.821417699412477, 5.339272331620044, 4.806542331570425, 4.786920383467598, 4.625417649979255, 4.587405202768952, 4.33219802369807, 3.7113166652349796, 3.587041726986771, 2.990975491441756, 2.713365516798865, 7.395405342220236, 8.19703344740371, 8.989747131506826, 6.94825539849878, 7.095949656074661, 27.500655221561058, 12.003680075858394, 11.424271392469599, 7.908606086585359, 6.489120496163406, 6.06822986012232, 6.000451638676327, 5.956577225997076, 5.813458241403269, 5.125189022540505, 3.9074454580516496, 3.7854168345330304, 3.779605981586176, 3.7347231825710376, 3.3295102142595066, 2.9047383226955326, 2.866967422723641, 2.8532680993933583, 2.829545757468994, 2.7892501555753335, 2.5066102113095594, 2.246719448548723, 2.2105965165777715, 2.17353315938249, 2.143555192838773, 2.14336198402424, 2.0803602545235393, 2.0709556464628998, 2.0351200369923816, 1.9910600655713655, 4.873398797296543, 4.845331925675217, 3.5497639930193174], \"Total\": [194.0, 82.0, 59.0, 121.0, 126.0, 99.0, 63.0, 69.0, 120.0, 36.0, 43.0, 136.0, 28.0, 84.0, 41.0, 36.0, 41.0, 57.0, 93.0, 60.0, 34.0, 58.0, 31.0, 83.0, 75.0, 67.0, 31.0, 62.0, 56.0, 48.0, 48.52247422561906, 40.932525417992295, 36.17318103797469, 35.62344334775988, 34.494017670462206, 31.501813185048217, 29.38213871113405, 27.84741047867771, 27.58859169335557, 25.15355972873292, 25.132761562008124, 30.081160715432574, 21.850592948989632, 21.230296792645127, 18.572249320030195, 17.132122855855282, 15.829065987008754, 15.150170747319695, 14.627599394553359, 14.469543825335547, 14.12068202468497, 13.535604209878818, 12.545815880864042, 121.33877258917646, 12.26602645420717, 12.101321386178508, 36.75589154483716, 11.649914233457283, 194.84331756393738, 11.11427217572465, 25.127571363144874, 32.601852627490466, 51.46981975621034, 83.67852331826201, 136.46308851066837, 67.63070973117587, 40.58773597457919, 56.14991944980036, 126.15368448843934, 68.10197742368779, 93.65931566381977, 29.20607509677439, 35.38665976307853, 69.27390822149773, 44.55744490247359, 39.497572726818284, 36.86440914918699, 36.41866896772388, 32.84394026888684, 32.38438026924884, 35.53767485674229, 30.298166160216667, 27.056849550394183, 24.44905017515005, 22.099284191894114, 21.660031280366407, 19.90896852278535, 18.992296562144983, 17.77496048391544, 16.995383756654636, 16.9978234524246, 16.870520140353662, 16.75118346325939, 16.030668020208363, 15.980302339466883, 15.839288600364757, 15.445756247988987, 15.344388657214848, 19.920620814326753, 14.53341782237098, 14.51533423969033, 14.471243119443107, 13.378187662842656, 99.96016009608623, 26.0288072955567, 41.36869226142029, 54.207941448971326, 75.71358567143423, 85.64432297532855, 62.9325438879519, 120.02673682579255, 47.33222141210157, 58.84132118981983, 24.965614590389308, 111.00211548727796, 93.65931566381977, 136.46308851066837, 57.776832245099264, 53.987491296866274, 36.53872412774249, 26.395598914892723, 25.33027970573652, 25.20070164755045, 23.194150178781054, 21.70359424151546, 20.21172023173735, 18.325167853816417, 23.353452911059303, 17.853360742392606, 16.901493315152475, 16.192917641000207, 15.78370375593589, 15.179329645953787, 14.879984060631818, 14.677451247701105, 13.757120111011956, 13.547452832340005, 13.4045773502393, 13.145298347830726, 12.417735653775244, 11.665132449272933, 11.328502227543789, 10.909905016696005, 10.886120213592264, 10.826527833760544, 10.733152837779999, 10.57716847370658, 10.530117515397471, 10.522083632677457, 32.54097252509066, 35.009723210044385, 32.35930651243253, 60.637304112087755, 55.164225275451514, 28.66779510661843, 84.5874948508088, 31.945847253257856, 35.52583008617929, 111.00211548727796, 53.987491296866274, 57.100473019066314, 85.64432297532855, 36.59413163320988, 41.8927662561599, 25.278478292019678, 21.483616674632582, 19.676860453168107, 18.040580112880566, 17.40164501215553, 17.387182175993146, 15.851505909178167, 15.719723808897921, 15.253567987522167, 14.81768973035033, 13.904465771306583, 13.531389669202971, 12.612457053368932, 12.313702328461845, 11.866618849530807, 11.5906303152922, 10.93307065832703, 10.685508139843854, 10.322442113257027, 9.97786580161628, 9.825718287043175, 9.401412265773729, 9.401363113800436, 9.363708029750184, 9.35108606051241, 9.335689112438878, 9.334323514042788, 8.809347068646943, 8.480038567760289, 30.05765874463454, 31.965679594002527, 120.02673682579255, 22.371706074025482, 34.318814934219674, 37.85601945237621, 126.15368448843934, 41.54318604355508, 27.31775648903699, 20.76225754349495, 18.722271728908126, 17.953631750935173, 16.17746667850478, 16.035854554992543, 15.817928410074593, 14.153089490179411, 13.771073681044223, 13.000419753936697, 11.752973842346158, 11.66996255440831, 11.371707477110828, 8.884739231604653, 8.610889421475441, 7.825185281963086, 7.662517480485458, 7.320962807134186, 7.3112981681029385, 7.291453816737686, 7.236981104939571, 6.846460581010117, 6.605035219750612, 6.4961302246279615, 6.348172520995576, 6.280328054626558, 6.238802766418276, 6.188936125664793, 6.151856841009209, 27.160172061223573, 38.125174879651674, 21.422183371332903, 30.83569253700522, 24.283203527794537, 63.74973808819521, 62.9325438879519, 35.38665976307853, 47.33222141210157, 126.15368448843934, 36.59413163320988, 16.73208430098759, 37.85601945237621, 40.58773597457919, 82.34414063971806, 31.630085262807228, 30.39531867371332, 29.981586575404663, 23.698331671457293, 23.212256134475457, 22.678875524382086, 21.974555104327692, 26.774281507720758, 18.70674536063874, 15.947708043591778, 14.683316560511264, 13.846398493948353, 13.818702200690296, 13.372038982832652, 12.635090125122908, 11.414272311615312, 10.660754431239795, 9.635625224059, 9.298668369012258, 8.095573362867453, 7.924801489894917, 7.885433649902079, 7.843253224336463, 7.1359818153418715, 7.091754824680627, 6.619599287535748, 6.346487355045521, 6.144483825604915, 5.896260359292257, 57.776832245099264, 14.42439953457373, 13.043093378360568, 58.84132118981983, 31.965679594002527, 120.02673682579255, 68.10197742368779, 22.197605304836173, 194.84331756393738, 34.01501069730313, 31.437467080610165, 24.822382794747117, 43.84488368697972, 20.83286287220973, 18.961421836263046, 13.589512502684, 13.187441264483507, 12.847567675852305, 12.798921455256465, 12.126179997972311, 11.980605660898526, 11.690973859858431, 10.822850057847129, 9.996470078073955, 9.62835364253208, 9.577294258236101, 9.48288277927153, 9.150452564810907, 8.980632970440691, 8.646124975225634, 8.532942795377096, 8.503405518000982, 8.385961468798044, 8.041733164486564, 7.858759045543778, 7.792989348437118, 7.6964730002446675, 7.690099856804016, 7.638914331086638, 20.144963473768673, 63.74973808819521, 75.71358567143423, 21.217942775561884, 36.434478837437815, 23.50957209137846, 22.92661650859256, 18.908192521870482, 18.744025501809787, 18.657752743507864, 16.894265268018714, 16.758610780467542, 14.979362757545982, 14.253268757824475, 12.34925631840278, 12.270823862609465, 12.197720992881978, 12.178988734282495, 11.812938508346393, 10.666235000798768, 10.053432324065538, 10.044153335531334, 9.12137805727494, 8.939429817314386, 8.29217493097791, 8.26791909396314, 7.376739446854925, 6.8991446014124564, 6.67297925944379, 6.627978535252851, 6.1966196931572, 6.140171982592812, 6.1250869696000505, 5.990588485870026, 19.54710713034661, 22.197605304836173, 20.290993685301924, 84.5874948508088, 36.59413163320988, 99.96016009608623, 59.60839139632278, 36.605101021415514, 17.49355163365328, 13.107029460656475, 12.750599190820783, 9.809925470094559, 9.246074301948186, 9.050563728921025, 8.80299267304966, 8.308266376803287, 7.577192082404022, 7.4992675680426215, 7.3053734415622715, 7.255864756782192, 7.054716244884329, 7.008489149757341, 6.7535648485907505, 6.726671525634121, 6.601040499725451, 6.600745487939071, 6.11876770745697, 5.58589649895403, 5.566278387954221, 5.4047199415565705, 5.366678566944126, 5.111377966463863, 4.490556257050206, 4.366630334601595, 3.770362188216677, 3.492664954579203, 10.550615050885703, 22.371706074025482, 56.14991944980036, 41.36869226142029, 60.637304112087755, 28.31631899090499, 12.784353753239273, 12.205072091935962, 8.68928191059085, 7.269823708686206, 6.849224955943353, 6.7811641262268685, 6.737384675596919, 6.5941317268265065, 5.905914401897606, 4.688178519239832, 4.566107489928047, 4.560322913210223, 4.515551314214488, 4.11028355900106, 3.6854727936326177, 3.6479648856338533, 3.6339573385769968, 3.6102203814228795, 3.5699927035077703, 3.2872709933168727, 3.0277013781066247, 2.9917364983630934, 2.9542525552359353, 2.9242286748160327, 2.924063034653301, 2.8610368373908175, 2.851658018642519, 2.8158443046153656, 2.77174062385002, 22.82807536011527, 67.63070973117587, 30.05765874463454], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9277, -4.0991, -4.2251, -4.2408, -4.2737, -4.3665, -4.438, -4.4931, -4.5026, -4.5978, -4.5986, -4.4192, -4.7432, -4.773, -4.912, -4.9963, -5.0791, -5.127, -5.1622, -5.1736, -5.1994, -5.2441, -5.3247, -3.056, -5.3487, -5.3631, -4.2544, -5.4037, -2.5899, -5.4541, -4.6683, -4.4291, -4.0294, -3.6258, -3.2732, -3.9267, -4.3477, -4.0943, -3.463, -3.99, -3.7735, -4.7198, -4.7189, -3.4593, -3.9067, -4.0297, -4.0998, -4.1122, -4.2178, -4.2322, -4.1394, -4.3004, -4.4166, -4.521, -4.6254, -4.6462, -4.7336, -4.7826, -4.8517, -4.8985, -4.8984, -4.9062, -4.9137, -4.9597, -4.963, -4.9723, -4.9988, -5.0057, -4.7456, -5.0628, -5.0642, -5.0674, -5.1504, -3.244, -4.5253, -4.1678, -3.9864, -3.7405, -3.6481, -3.9591, -3.5009, -4.2203, -4.0831, -4.6967, -3.9602, -4.0659, -4.0442, -4.5593, -4.5928, -3.924, -4.2547, -4.2971, -4.3024, -4.388, -4.4567, -4.5306, -4.6326, -4.3905, -4.6598, -4.717, -4.7619, -4.7888, -4.8298, -4.8508, -4.8652, -4.9336, -4.9498, -4.9611, -4.9818, -5.0422, -5.1089, -5.1403, -5.1806, -5.183, -5.1889, -5.1982, -5.2139, -5.2187, -5.2196, -4.1414, -4.0784, -4.1674, -3.5908, -3.6925, -4.3726, -3.4898, -4.3109, -4.2712, -3.5516, -4.0561, -4.2444, -4.6367, -4.8197, -3.3648, -3.8823, -4.0505, -4.1417, -4.2322, -4.2699, -4.2708, -4.3677, -4.3765, -4.4082, -4.4387, -4.5059, -4.5347, -4.6094, -4.635, -4.6745, -4.6996, -4.7623, -4.787, -4.8243, -4.861, -4.8776, -4.9256, -4.9256, -4.93, -4.9314, -4.9332, -4.9334, -4.9966, -5.0384, -3.8307, -4.1118, -3.6029, -4.4804, -4.2987, -4.2937, -3.7616, -3.3374, -3.7665, -4.0501, -4.1577, -4.2015, -4.3106, -4.3198, -4.3342, -4.4514, -4.4804, -4.5415, -4.6491, -4.6567, -4.6844, -4.9518, -4.9861, -5.0917, -5.1151, -5.1659, -5.1673, -5.1703, -5.1787, -5.241, -5.2815, -5.3004, -5.3266, -5.3388, -5.3464, -5.3555, -5.3625, -3.9503, -3.6384, -4.2835, -4.1884, -4.383, -3.8831, -4.1028, -4.4732, -4.3612, -3.9583, -4.5516, -4.9573, -4.7617, -4.8961, -2.5996, -3.5715, -3.6124, -3.6264, -3.8686, -3.89, -3.914, -3.9467, -3.7499, -4.114, -4.2809, -4.3679, -4.4299, -4.432, -4.4668, -4.527, -4.6355, -4.7089, -4.8183, -4.857, -5.0089, -5.0324, -5.038, -5.0439, -5.1492, -5.1562, -5.2336, -5.2814, -5.3182, -5.3655, -3.488, -4.6678, -4.8331, -3.9353, -4.5331, -4.1004, -4.6122, -4.9499, -4.9246, -3.3997, -3.4804, -3.7233, -3.1592, -3.9046, -4.0025, -4.3523, -4.3842, -4.4119, -4.4159, -4.4734, -4.4864, -4.5125, -4.5953, -4.681, -4.7217, -4.7275, -4.7382, -4.7771, -4.7976, -4.8391, -4.8536, -4.8574, -4.8727, -4.9189, -4.9443, -4.9537, -4.9675, -4.9684, -4.9758, -4.0505, -3.229, -4.4112, -4.7171, -3.1855, -3.6355, -3.6614, -3.8615, -3.8706, -3.8754, -3.9792, -3.9876, -4.1056, -4.158, -4.3102, -4.317, -4.3234, -4.325, -4.3577, -4.4672, -4.5311, -4.5321, -4.6369, -4.6589, -4.7414, -4.7447, -4.8711, -4.9461, -4.9837, -4.9914, -5.0678, -5.0783, -5.081, -5.1065, -4.0058, -4.1395, -4.245, -3.8883, -4.5274, -4.6697, -2.2864, -2.7803, -3.5427, -3.8471, -3.8765, -4.1584, -4.2228, -4.2462, -4.2766, -4.3402, -4.4424, -4.4539, -4.4832, -4.4908, -4.5224, -4.5297, -4.5715, -4.576, -4.5974, -4.5974, -4.6839, -4.789, -4.7931, -4.8274, -4.8357, -4.8929, -5.0476, -5.0817, -5.2634, -5.3608, -4.3581, -4.2552, -4.1629, -4.4205, -4.3995, -2.6314, -3.4604, -3.5098, -3.8776, -4.0754, -4.1425, -4.1537, -4.1611, -4.1854, -4.3114, -4.5827, -4.6144, -4.6159, -4.6279, -4.7427, -4.8792, -4.8923, -4.8971, -4.9055, -4.9198, -5.0266, -5.1361, -5.1523, -5.1692, -5.1831, -5.1832, -5.213, -5.2176, -5.235, -5.2569, -4.3618, -4.3676, -4.6787], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.6365, 1.6353, 1.6328, 1.6325, 1.6317, 1.6297, 1.6279, 1.6265, 1.6262, 1.6235, 1.6235, 1.6232, 1.6189, 1.6178, 1.6126, 1.6091, 1.6053, 1.6013, 1.6012, 1.6006, 1.5993, 1.5968, 1.5922, 1.5917, 1.5908, 1.5899, 1.5876, 1.5873, 1.5842, 1.584, 1.554, 1.5328, 1.4759, 1.3935, 1.257, 1.3055, 1.3951, 1.324, 1.1458, 1.2353, 1.1332, 1.3521, 1.1611, 1.7489, 1.7428, 1.7403, 1.7393, 1.739, 1.7367, 1.7364, 1.7363, 1.7348, 1.7317, 1.7287, 1.7254, 1.7247, 1.7215, 1.7196, 1.7168, 1.7148, 1.7148, 1.7145, 1.7141, 1.712, 1.7119, 1.7114, 1.7102, 1.7098, 1.7089, 1.707, 1.7069, 1.7067, 1.7023, 1.5975, 1.6617, 1.5559, 1.467, 1.3788, 1.348, 1.3452, 1.1576, 1.3688, 1.2884, 1.5321, 0.7766, 0.8407, 0.486, 0.8304, 0.8647, 1.9239, 1.9184, 1.9172, 1.917, 1.9144, 1.9121, 1.9094, 1.9054, 1.905, 1.9043, 1.9018, 1.8998, 1.8985, 1.8965, 1.8955, 1.8948, 1.8911, 1.8903, 1.8896, 1.8885, 1.8849, 1.8808, 1.8787, 1.876, 1.8758, 1.8754, 1.8747, 1.8736, 1.8733, 1.8732, 1.8224, 1.8122, 1.802, 1.7506, 1.7435, 1.7179, 1.5187, 1.6713, 1.6048, 1.1851, 1.4015, 1.1571, 0.3594, 1.0267, 2.3464, 2.3341, 2.3285, 2.3251, 2.3214, 2.3198, 2.3198, 2.3153, 2.3149, 2.3133, 2.3117, 2.3082, 2.3065, 2.3022, 2.3006, 2.2981, 2.2965, 2.2922, 2.2904, 2.2877, 2.2849, 2.2836, 2.2798, 2.2798, 2.2795, 2.2793, 2.2792, 2.2792, 2.2738, 2.2701, 2.2125, 1.8698, 1.0557, 1.8581, 1.6119, 1.5188, 0.8471, 2.3821, 2.3722, 2.3631, 2.3588, 2.357, 2.3521, 2.3516, 2.3509, 2.3449, 2.3433, 2.3398, 2.3331, 2.3326, 2.3307, 2.3102, 2.3072, 2.2973, 2.2949, 2.2897, 2.2896, 2.2893, 2.2884, 2.2815, 2.2769, 2.2747, 2.2716, 2.27, 2.2691, 2.268, 2.2671, 2.1943, 2.167, 2.0984, 1.8292, 1.8735, 1.4082, 1.2014, 1.4067, 1.2279, 0.6504, 1.2948, 1.6716, 1.0508, 0.8467, 2.4357, 2.4206, 2.4196, 2.4193, 2.4123, 2.4116, 2.4108, 2.4097, 2.4089, 2.4034, 2.396, 2.3917, 2.3884, 2.3883, 2.3863, 2.3828, 2.3759, 2.3708, 2.3626, 2.3594, 2.3461, 2.3438, 2.3433, 2.3427, 2.332, 2.3312, 2.3226, 2.317, 2.3125, 2.3065, 1.9017, 2.1096, 2.045, 1.4361, 1.4485, 0.5582, 0.6131, 1.3964, -0.7505, 2.5198, 2.5179, 2.5113, 2.5064, 2.5052, 2.5014, 2.4847, 2.4829, 2.4812, 2.481, 2.4775, 2.4766, 2.475, 2.4693, 2.4631, 2.4599, 2.4594, 2.4586, 2.4553, 2.4536, 2.45, 2.4488, 2.4484, 2.447, 2.4427, 2.4403, 2.4394, 2.438, 2.4379, 2.4372, 2.3929, 2.0623, 0.7081, 1.6743, 2.6653, 2.6534, 2.6525, 2.6452, 2.6448, 2.6446, 2.6401, 2.6397, 2.634, 2.6313, 2.6225, 2.622, 2.6216, 2.6215, 2.6194, 2.612, 2.6072, 2.6071, 2.5987, 2.5969, 2.5895, 2.5892, 2.5768, 2.5687, 2.5645, 2.5636, 2.5545, 2.5532, 2.5528, 2.5496, 2.4676, 2.2068, 2.1911, 1.1201, 1.3189, 0.1718, 3.072, 3.0658, 3.0417, 3.026, 3.0242, 3.0045, 2.9993, 2.9973, 2.9946, 2.9888, 2.9787, 2.9776, 2.9745, 2.9737, 2.9702, 2.9694, 2.9647, 2.9642, 2.9617, 2.9617, 2.951, 2.937, 2.9365, 2.9316, 2.9304, 2.9219, 2.8967, 2.8906, 2.8557, 2.8348, 2.732, 2.0833, 1.2554, 1.3033, 0.9419, 3.4715, 3.4377, 3.4346, 3.4066, 3.3871, 3.3796, 3.3784, 3.3775, 3.3747, 3.3589, 3.3186, 3.3132, 3.3129, 3.3109, 3.29, 3.2627, 3.2598, 3.2589, 3.2571, 3.2539, 3.2296, 3.2024, 3.1981, 3.1938, 3.1901, 3.1901, 3.1821, 3.1808, 3.176, 3.1699, 1.9565, 0.8647, 1.3645]}, \"token.table\": {\"Topic\": [9, 2, 6, 10, 9, 10, 2, 10, 4, 2, 5, 2, 5, 8, 7, 5, 3, 5, 7, 4, 8, 8, 10, 7, 3, 8, 9, 2, 4, 7, 3, 3, 2, 3, 10, 1, 2, 7, 8, 9, 10, 9, 7, 1, 6, 2, 4, 10, 7, 3, 1, 6, 5, 5, 1, 4, 4, 8, 5, 2, 6, 4, 3, 1, 2, 7, 8, 4, 4, 1, 4, 9, 1, 2, 3, 10, 10, 2, 3, 2, 2, 1, 3, 1, 1, 8, 1, 10, 7, 10, 9, 9, 1, 7, 5, 10, 3, 3, 3, 2, 6, 8, 3, 6, 6, 1, 2, 6, 5, 3, 2, 6, 6, 5, 6, 3, 5, 6, 7, 6, 2, 6, 10, 2, 7, 3, 5, 6, 9, 4, 9, 7, 5, 7, 1, 5, 1, 10, 8, 4, 5, 8, 5, 3, 5, 1, 3, 9, 8, 2, 3, 7, 2, 4, 9, 1, 2, 8, 2, 3, 7, 2, 4, 3, 7, 9, 7, 2, 6, 5, 8, 9, 1, 1, 2, 8, 4, 2, 3, 5, 6, 7, 8, 4, 3, 8, 3, 9, 8, 9, 1, 3, 5, 9, 2, 1, 2, 1, 5, 2, 6, 8, 9, 1, 4, 5, 1, 2, 3, 2, 6, 9, 7, 4, 4, 3, 10, 7, 3, 5, 9, 4, 8, 3, 5, 6, 2, 5, 8, 10, 8, 8, 1, 3, 5, 8, 9, 4, 9, 4, 10, 8, 2, 2, 9, 5, 4, 1, 2, 3, 7, 8, 2, 5, 1, 5, 3, 4, 5, 8, 1, 4, 3, 7, 2, 3, 6, 7, 4, 2, 3, 8, 5, 2, 6, 8, 5, 10, 8, 4, 1, 8, 8, 3, 3, 6, 9, 1, 3, 1, 9, 4, 3, 5, 5, 7, 6, 7, 10, 2, 6, 7, 1, 8, 7, 1, 1, 3, 7, 5, 6, 8, 6, 1, 8, 6, 9, 10, 5, 1, 10, 5, 3, 9, 9, 6, 10, 4, 7, 3, 6, 7, 8, 8, 1, 3, 4, 4, 7, 4, 6, 10, 2, 5, 2, 10, 6, 1, 3, 6, 8, 10, 3, 5, 8, 2, 8, 6, 9, 2, 7, 10, 3, 6, 7, 10, 3, 9, 3, 1, 7, 1, 5, 3, 5, 7, 9, 6, 10, 2, 9, 2, 3, 5, 4, 5, 4, 7, 2, 9, 10, 10, 1, 5, 9, 3, 5, 1, 4, 5, 9, 3, 4, 1, 5, 7, 2, 5, 1, 7, 5, 2, 3, 1, 5, 10, 7, 3, 4, 3, 1, 4, 10, 4, 2, 1, 5, 2, 3, 6, 10, 7, 1, 2, 3, 4, 7, 5, 6, 2, 4, 5, 6, 5, 8, 1, 4, 6, 7, 6, 8, 1, 1, 4, 5, 6, 8], \"Freq\": [0.8951114652654699, 0.3066757159491236, 0.690020360885528, 0.853209830552396, 0.826917287066533, 0.6839410396404183, 0.969527685725704, 0.7215682386694423, 0.9514403061372299, 0.9412969869220362, 0.9553641064307067, 0.9357064834160936, 0.9290561762468008, 0.8960436683261668, 0.9102612619271215, 0.9083978813706527, 0.4781233381383221, 0.4781233381383221, 0.9860845315722021, 0.9490424334806928, 0.9779294474729855, 0.93461919753211, 0.8223763369582803, 0.900317805156083, 0.9698179704090351, 0.9595833729654231, 0.8652320691727913, 0.4241693030846468, 0.14138976769488226, 0.4241693030846468, 0.9538440812189914, 0.9165982641183833, 0.9775560522541301, 0.9449652176543901, 0.6990472733038775, 0.9206354181245738, 0.09928039842833454, 0.8438833866408436, 0.8991486061504881, 0.891971605441873, 0.8466089515949418, 0.9897935276884471, 0.949295899613163, 0.9604299740466766, 0.9622197583270782, 0.9537855359575617, 0.9448166519052227, 0.8760196751441417, 0.9099566594710431, 0.9223068690475307, 0.9476238214125088, 0.8137380033721152, 0.8014358182492315, 0.8290749848586346, 0.9675676563600231, 0.9146561210947294, 0.9889835816538216, 0.9120714848559576, 0.9883681337753885, 0.9711405358965817, 0.9958207027598505, 0.9573079872629037, 0.942044848091035, 0.9786653954686159, 0.9386555824387747, 0.966869304951612, 0.9603059918085393, 0.9462823334226474, 0.977731746750331, 0.9869941832726682, 0.9433919357884389, 0.9155392559405273, 0.709736748154712, 0.16264800478545485, 0.059144729012892666, 0.07393091126611584, 0.7102665430478028, 0.1142539738461111, 0.8854682973073611, 0.9816332261608076, 0.9551563944776217, 0.1744117390753106, 0.8022939997464288, 0.9892323251450521, 0.908991642232031, 0.9717184331268337, 0.744697033447771, 0.21902853924934443, 0.9375429077450479, 0.9386473678389465, 0.8561046285143699, 0.8982662474841927, 0.02280767824905788, 0.9579224864604309, 0.9230471190260024, 0.8255462903080626, 0.9408612228987526, 0.9822556684658854, 0.9316926863093434, 0.9414321105715022, 0.360399236320192, 0.630698663560336, 0.952201674815974, 0.9710811471263017, 0.9407540455825585, 0.9640585439617726, 0.6288098100421544, 0.3568920543482498, 0.9482910537416741, 0.9128739175387581, 0.9717310242333455, 0.8924868035982859, 0.8408093175210188, 0.9600280240315522, 0.9063992757533812, 0.8652843035817942, 0.12361204336882774, 0.9678805225479846, 0.9701599183273634, 0.8833028825928131, 0.9609396671099579, 0.9705324543035924, 0.8905532768126249, 0.9470122287976097, 0.9408968090989471, 0.23340291292114435, 0.746889321347662, 0.97217784189006, 0.9581987910672823, 0.5810911316724996, 0.357594542567692, 0.9347392435030217, 0.3764721349411187, 0.6117672192793179, 0.915329208207307, 0.07959384419193974, 0.9840703396309138, 0.668508072517177, 0.9647649822380855, 0.3294458241822668, 0.5765301923189668, 0.0823614560455667, 0.9359333346226654, 0.9503472842588573, 0.8945475088155262, 0.8895200015580305, 0.09201931050600315, 0.9334244893234374, 0.9470669334338214, 0.6867988028682009, 0.14528436214519636, 0.15849203143112328, 0.9220553107747265, 0.07683794256456054, 0.9089476121604694, 0.18447481554734016, 0.7378992621893606, 0.055342444664202045, 0.28148532984990904, 0.7037133246247727, 0.9181505769696636, 0.9960460117159561, 0.9774890474934034, 0.8245749169121247, 0.04947449501472748, 0.11544048836769746, 0.8742736977583927, 0.9644972529615463, 0.8646700716847805, 0.9451538974651286, 0.8068915388693931, 0.9160381560819606, 0.9691879367884092, 0.5979116930664548, 0.3950487972046219, 0.895216649388103, 0.9178180483053132, 0.3783711672126974, 0.4684595403585778, 0.018017674629176066, 0.06306186120211624, 0.04504418657294017, 0.03603534925835213, 0.9611576921669687, 0.9236571644712197, 0.9018078054432536, 0.9595899805583272, 0.9089882363989404, 0.8770604561905465, 0.9238250692173431, 0.9420499484928848, 0.9429811489783478, 0.9614217900815475, 0.888419691602133, 0.9874024479868749, 0.9772179847573638, 0.9674358923035464, 0.7532679391908346, 0.239676162469811, 0.3980834377078695, 0.5884711687855463, 0.017307975552516067, 0.8504948734615445, 0.9675495073650217, 0.9786892502944078, 0.956158388508488, 0.9549288859796267, 0.9874892982823922, 0.9466619133384935, 0.9483999228766272, 0.9477751698304336, 0.9717866535058662, 0.9539752871231159, 0.9607291134027129, 0.9159635699985395, 0.9485150277299872, 0.6769901904477744, 0.9252699935431165, 0.7512713564844478, 0.21912081230796393, 0.9411322417411456, 0.344980640601675, 0.5913953838885857, 0.18360571517630123, 0.7868816364698624, 0.9800795585098178, 0.6673812530886849, 0.3019105668734527, 0.03178005967088976, 0.6839797830271929, 0.9375379409183395, 0.9052533842840977, 0.08275454914873943, 0.6502143147400955, 0.047288313799279676, 0.21279741209675854, 0.9087818537543465, 0.9358469311077731, 0.8589429673369402, 0.865004164858354, 0.13307756382436214, 0.9489287306988254, 0.9765516613683186, 0.8218775634758896, 0.16921008659797726, 0.9632863843491926, 0.90199649694047, 0.67417498023876, 0.2784635787942704, 0.021983966746916085, 0.014655977831277391, 0.007327988915638696, 0.9881306893615676, 0.8763652297425144, 0.7637775119907118, 0.22174185831988405, 0.9503821057783584, 0.9656011966553776, 0.8078932951441502, 0.9519683057584691, 0.9783119288711525, 0.9624550497941657, 0.9869610715091425, 0.9239710378089808, 0.6655432376576778, 0.2101715487340035, 0.05838098575944542, 0.0700571829113345, 0.9769191354107631, 0.8503387741505631, 0.06002391346945152, 0.08003188462593536, 0.9425908565443313, 0.9848702860018349, 0.9534630641725079, 0.8143094385914332, 0.9673129582466831, 0.8858276036878187, 0.9783249099814398, 0.9640423852598513, 0.9250217739522016, 0.0544130455266001, 0.9031948579635538, 0.9852560772002037, 0.9663597562854993, 0.9672603525188388, 0.8839228405669411, 0.9395183218638303, 0.05768972151795449, 0.9570948466918606, 0.8907582426386421, 0.9745241260431677, 0.9186009160099237, 0.8127627363935459, 0.8100095960514653, 0.14727447200935734, 0.9700657325954178, 0.8908058069327188, 0.8403378519659964, 0.974304536484427, 0.6932697597588778, 0.20798092792766337, 0.9695695052390398, 0.9647464111809105, 0.909507510749076, 0.9610723173062009, 0.7767823501471183, 0.15535647002942365, 0.05975248847285525, 0.9236268043477569, 0.8479951181464047, 0.8346425416790817, 0.9380199182429764, 0.9339181218007461, 0.954733074811206, 0.9869940934669258, 0.9834694891003988, 0.8771308690472127, 0.9468836297767164, 0.9442129598181247, 0.8760115251862992, 0.9272156325891683, 0.18956240848083108, 0.6634684296829088, 0.9251173148779268, 0.9405740285060842, 0.8848038313649372, 0.9349514187612264, 0.8982432397913964, 0.9263309017283112, 0.9637057623731525, 0.937579001633114, 0.931182363493045, 0.8163149396597849, 0.8997440265896673, 0.9675816717873578, 0.9081263273724947, 0.9573029823152115, 0.8704591232786726, 0.5943874881222554, 0.375402624077214, 0.9012646477744144, 0.9632971521984387, 0.9354038444636527, 0.950257022700431, 0.6605671267523422, 0.9388722999472913, 0.6607737646153536, 0.17620633723076096, 0.16152247579486423, 0.8696730314612662, 0.7298766513152936, 0.40990178836180424, 0.3279214306894434, 0.24594107301708254, 0.9543437661401163, 0.9675953415946266, 0.9340338370081144, 0.7956795263266083, 0.9564015636143495, 0.9340289386102745, 0.8253295045973422, 0.945432610330322, 0.8877127512304825, 0.9490784827239398, 0.814006823000591, 0.9523544358271009, 0.9316749526974337, 0.9850126941173697, 0.9240819944208761, 0.9600216793381413, 0.621703210964099, 0.36737007920605846, 0.4215893638321563, 0.5513091680882044, 0.8907258715317493, 0.7825678371359548, 0.9454048616720145, 0.9126111008490314, 0.9901589370577756, 0.9174381627502057, 0.4075018022050045, 0.5742070849252335, 0.9869247861012492, 0.9269700273920003, 0.9185273652809501, 0.9423200303776477, 0.9397226144806347, 0.9885040013929414, 0.9628964259422438, 0.9206744679614175, 0.7013463700503836, 0.7123785820523064, 0.10685678730784597, 0.16028518096176894, 0.8911841825759694, 0.09219146716303132, 0.29057466049324776, 0.4226540516265422, 0.2641587822665889, 0.8171580028943536, 0.97100214830297, 0.964183423304343, 0.8354410449399645, 0.07771544604092694, 0.058286584530695205, 0.6760722198391995, 0.3169088530496248, 0.985678163814323, 0.9566200404490177, 0.9004203490342775, 0.801101848608171, 0.1602203697216342, 0.9564941900911708, 0.9135378833167133, 0.9098999305079944, 0.916360584319349, 0.9496570181080775, 0.9542152382797888, 0.940048634265447, 0.49535509989446375, 0.4662165646065541, 0.9888290921215223, 0.9687630010690089, 0.947752681783476, 0.9541393050855062, 0.9440077296147503, 0.09063845227651618, 0.8157460704886457, 0.07251076182121295, 0.8309742018623317, 0.9071282136533825, 0.31523381590883937, 0.1926428874998463, 0.4553377340905458, 0.0350259795454266, 0.9407995400271909, 0.9574223125708315, 0.9556507469798211, 0.549877483512634, 0.2666072647333983, 0.02499443106875609, 0.14996658641253655, 0.15347539561711113, 0.8185354432912594, 0.9340838694161381, 0.005132328952835923, 0.041058631622687386, 0.020529315811343693, 0.9497360035556747, 0.8949116625430802, 0.9824990711404914, 0.6024397964132756, 0.22195150394173313, 0.1743904673827903, 0.8460529372954185, 0.9880750637500166], \"Term\": [\"ability\", \"accelerate\", \"accelerate\", \"accelerator\", \"access\", \"accessible\", \"action\", \"administer\", \"advocate\", \"african\", \"age\", \"ago\", \"agriculture\", \"ahead\", \"ai\", \"almost\", \"always\", \"always\", \"alzheimer\", \"amazing\", \"annual\", \"answer\", \"app\", \"approach\", \"area\", \"ask\", \"author\", \"avoid\", \"avoid\", \"avoid\", \"bad\", \"bear\", \"beat\", \"become\", \"begin\", \"benefit\", \"big\", \"big\", \"black\", \"blog\", \"blood\", \"book\", \"breakthrough\", \"brilliant\", \"bring\", \"build\", \"call\", \"candidate\", \"carbon\", \"care\", \"case\", \"catalyst\", \"catch\", \"century\", \"challenge\", \"chance\", \"change\", \"check\", \"child\", \"climate\", \"climate_change\", \"climate_disaster\", \"close\", \"come\", \"commit\", \"commitment\", \"community\", \"company\", \"congratulation\", \"continue\", \"contribute\", \"conversation\", \"country\", \"country\", \"country\", \"country\", \"course\", \"covid\", \"covid\", \"create\", \"critical\", \"datum\", \"datum\", \"day\", \"death\", \"decade\", \"develop\", \"develop\", \"diagnose\", \"diagnostic\", \"discuss\", \"discussion\", \"disease\", \"disease\", \"drive\", \"drug\", \"early\", \"easy\", \"economic\", \"education\", \"effort\", \"effort\", \"electricity\", \"emission\", \"encourage\", \"end\", \"energy\", \"energy\", \"enjoy\", \"enough\", \"ensure\", \"entire\", \"entrepreneur\", \"epidemic\", \"equal\", \"even\", \"even\", \"event\", \"ever\", \"everywhere\", \"excite\", \"excited\", \"exciting\", \"explain\", \"face\", \"family\", \"family\", \"farmer\", \"fascinating\", \"favorite\", \"favorite\", \"female\", \"fight\", \"fight\", \"find\", \"find\", \"first\", \"forever\", \"forward\", \"foundation\", \"foundation\", \"foundation\", \"free\", \"friend\", \"fun\", \"future\", \"future\", \"gene\", \"generation\", \"get\", \"get\", \"get\", \"give\", \"give\", \"glad\", \"global\", \"global\", \"global\", \"go\", \"go\", \"goal\", \"good\", \"government\", \"great\", \"great\", \"great\", \"greenhouse_gas\", \"grow\", \"growth\", \"guest\", \"guide\", \"hand\", \"hard\", \"health\", \"health\", \"healthy\", \"hear\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hero\", \"high\", \"history\", \"home\", \"hopeful\", \"human\", \"humanity\", \"idea\", \"identify\", \"impact\", \"importance\", \"important\", \"improve\", \"increase\", \"incredible\", \"incredible\", \"innovation\", \"innovation\", \"innovation\", \"innovative\", \"insight\", \"inspire\", \"interested\", \"invest\", \"investment\", \"issue\", \"job\", \"join\", \"keep\", \"key\", \"kid\", \"kind\", \"know\", \"language\", \"large\", \"last\", \"last\", \"late\", \"lead\", \"lead\", \"leader\", \"leader\", \"leadership\", \"learn\", \"learn\", \"learn\", \"leone\", \"lesson\", \"letter\", \"life\", \"life\", \"life\", \"life\", \"lift\", \"list\", \"listen\", \"live\", \"live\", \"long\", \"look\", \"lot\", \"lot\", \"love\", \"low\", \"make\", \"make\", \"make\", \"make\", \"make\", \"malaria\", \"man\", \"many\", \"many\", \"matter\", \"meet\", \"melinda\", \"million\", \"mind\", \"miss\", \"much\", \"nearly\", \"need\", \"need\", \"need\", \"need\", \"never\", \"new\", \"new\", \"new\", \"news\", \"next\", \"nuclear\", \"often\", \"old\", \"one\", \"opportunity\", \"optimism\", \"optimistic\", \"optimistic\", \"organization\", \"pandemic\", \"part\", \"partner\", \"partnership\", \"people\", \"people\", \"person\", \"piece\", \"place\", \"plan\", \"plant\", \"polio\", \"polio\", \"poor\", \"population\", \"positive\", \"possible\", \"potential\", \"potential\", \"poverty\", \"power\", \"president\", \"problem\", \"progress\", \"progress\", \"progress\", \"project\", \"promise\", \"provide\", \"public\", \"put\", \"question\", \"reach\", \"read\", \"reality\", \"really\", \"reason\", \"receive\", \"recently\", \"recommend\", \"recommend\", \"recommendation\", \"reduce\", \"reliable\", \"remarkable\", \"renewable\", \"report\", \"require\", \"research\", \"researcher\", \"response\", \"rest\", \"right\", \"risk\", \"safe\", \"sanitation\", \"save\", \"save\", \"say\", \"school\", \"science\", \"scientist\", \"seattle\", \"sector\", \"see\", \"see\", \"see\", \"series\", \"serve\", \"share\", \"share\", \"share\", \"show\", \"sit\", \"slow\", \"software\", \"solution\", \"solve\", \"soon\", \"source\", \"speak\", \"spread\", \"stand\", \"start\", \"stay\", \"step\", \"still\", \"stop\", \"story\", \"story\", \"student\", \"student\", \"success\", \"summer\", \"summit\", \"supply\", \"support\", \"tackle\", \"take\", \"take\", \"talk\", \"teach\", \"teacher\", \"team\", \"tech\", \"technology\", \"tell\", \"test\", \"testing\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"thinker\", \"thought\", \"thrill\", \"time\", \"time\", \"time\", \"today\", \"today\", \"together\", \"toilet\", \"tomorrow\", \"tool\", \"tool\", \"tough\", \"travel\", \"treatment\", \"trial\", \"try\", \"turn\", \"understand\", \"use\", \"use\", \"vaccine\", \"visit\", \"wait\", \"want\", \"watch\", \"way\", \"way\", \"way\", \"wealthy\", \"week\", \"well\", \"well\", \"well\", \"well\", \"win\", \"wish\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"world\", \"worst_effect\", \"worth\", \"write\", \"year\", \"year\", \"year\", \"yield\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 3, 4, 5, 9, 7, 10, 1, 2, 8]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el139331323767259115042788611779\", ldavis_el139331323767259115042788611779_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el139331323767259115042788611779\", ldavis_el139331323767259115042788611779_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el139331323767259115042788611779\", ldavis_el139331323767259115042788611779_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip\n",
        "\n",
        "mallet_path = \"/content/mallet-2.0.8/bin/mallet\"\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8l8HH8Y3iaPR",
        "outputId": "87d3eee2-f562-4b2b-f29a-31471f1ecafc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-06 05:19:51--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip [following]\n",
            "--2023-11-06 05:19:51--  https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16184794 (15M) [application/zip]\n",
            "Saving to: mallet-2.0.8.zip.2\n",
            "\n",
            "mallet-2.0.8.zip.2  100%[===================>]  15.43M  5.59MB/s    in 2.8s    \n",
            "\n",
            "2023-11-06 05:19:54 (5.59 MB/s) - mallet-2.0.8.zip.2 saved [16184794/16184794]\n",
            "\n",
            "Archive:  mallet-2.0.8.zip\n",
            "replace mallet-2.0.8/bin/classifier2info? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ad3fb0a2ab05>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/mallet-2.0.8/bin/mallet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gensim.models' has no attribute 'wrappers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Doqs7KPdCAPg",
        "outputId": "ea8de21f-8c98-4daa-e0ef-d4ce4054c315"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3be558840627>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show Topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamallet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute Coherence Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcoherence_model_ldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mldamallet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ldamallet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the optimal number of topics\n",
        "\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "id": "aaZ0uwYOikX2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Kow0WtShil3e",
        "outputId": "d1085967-1150-4a28-a469-4a08300a2b67"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-51428e9aa331>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Can take a long time to run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-509184f410c6>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcoherencemodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gensim.models' has no attribute 'wrappers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show graph\n",
        "limit=40; start=2; step=2;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "eGKVV5i4iybd",
        "outputId": "a9e35d8f-e01d-47ba-ee69-f3bce7facb5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4813e4711350>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num Topics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coherence score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'coherence_values' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Q_IvFVYti2aO",
        "outputId": "f862b7bc-f39d-4f1d-c3df-3f63d1eb0134"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-374779cc73b5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the coherence scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num Topics =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" has Coherence Value of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'coherence_values' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[14]\n",
        "#model_list[4] indicates that: model_list is a list that has been defined earlier and contains the number of topics and its coherence values.\n",
        "# Since I have decided 10 to be the ideal number of topics, Topics number 30 is present in the 14th place of the list.\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "E3LZUQK1i5o5",
        "outputId": "a5c07d23-ebd6-41f1-c168-3282546fcdd2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-69d3c7d93a4c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the model and print the topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#model_list[4] indicates that: model_list is a list that has been defined earlier and contains the number of topics and its coherence values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Since I have decided 10 to be the ideal number of topics, Topics number 30 is present in the 14th place of the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI4MhXAbZAAA"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QkLrBB4dZAAB"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "from gensim.models import LsiModel\n",
        "LSAModel = LsiModel(corpus, 20, id2word)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining compute for Coherence Values in LSI\n",
        "def computeCoherenceValuesLSI(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    modelList = []\n",
        "#providning start,stop and step\n",
        "    for num_topics in range(start, stop, step):\n",
        "        # generate LSA model\n",
        "        LSAModel = LsiModel(doc_term_matrix, num_topics=20, id2word = dictionary)\n",
        "        modelList.append(LSAModel)\n",
        "        coherencemodel = CoherenceModel(model=LSAModel, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    return modelList, coherence_values"
      ],
      "metadata": {
        "id": "S_WUMOze8M5P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking all the values from above and plotting a graph\n",
        "start,stop,step=2,40,2\n",
        "modelListLSA, coherenceValuesLSA = computeCoherenceValuesLSI(id2word, corpus,data_lemmatized,stop, start, step)\n",
        "x = range(start, stop, step)\n",
        "plt.plot(x, coherence_values)\n",
        "# giving labels to axis\n",
        "plt.xlabel(\"Topics Count\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"conValues\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "EjNcr2gZ8Q0S",
        "outputId": "3eef81ab-208e-4dc5-b70a-87d289fdee28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3831c32cdffc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelListLSA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherenceValuesLSA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeCoherenceValuesLSI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# giving labels to axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Topics Count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'coherence_values' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the topics count and the coherence values\n",
        "\n",
        "for numberOfTopics, cv in zip(range(2, 40, 2), coherenceValuesLSA):\n",
        "  print(\"Topics Count:\", numberOfTopics, \" - Coherence Value:\", round(cv, 4))\n",
        "#pprint(LSAModel.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhHgCPvR8kFe",
        "outputId": "12636c0a-021a-4903-f1bd-f62c7fab5644"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics Count: 2  - Coherence Value: 0.2489\n",
            "Topics Count: 4  - Coherence Value: 0.2412\n",
            "Topics Count: 6  - Coherence Value: 0.2397\n",
            "Topics Count: 8  - Coherence Value: 0.2491\n",
            "Topics Count: 10  - Coherence Value: 0.2453\n",
            "Topics Count: 12  - Coherence Value: 0.2477\n",
            "Topics Count: 14  - Coherence Value: 0.2358\n",
            "Topics Count: 16  - Coherence Value: 0.2464\n",
            "Topics Count: 18  - Coherence Value: 0.2447\n",
            "Topics Count: 20  - Coherence Value: 0.25\n",
            "Topics Count: 22  - Coherence Value: 0.2541\n",
            "Topics Count: 24  - Coherence Value: 0.2524\n",
            "Topics Count: 26  - Coherence Value: 0.2454\n",
            "Topics Count: 28  - Coherence Value: 0.2508\n",
            "Topics Count: 30  - Coherence Value: 0.2538\n",
            "Topics Count: 32  - Coherence Value: 0.2393\n",
            "Topics Count: 34  - Coherence Value: 0.2448\n",
            "Topics Count: 36  - Coherence Value: 0.2445\n",
            "Topics Count: 38  - Coherence Value: 0.2532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_corpus(doc_clean):\n",
        "    \"\"\"\n",
        "    Input  : clean document\n",
        "    Purpose: create term dictionary of our courpus and Converting list of documents (corpus) into Document Term Matrix\n",
        "    Output : term dictionary and Document Term Matrix\n",
        "    \"\"\"\n",
        "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
        "    dictionary = corpora.Dictionary(doc_clean)\n",
        "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
        "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
        "    # generate LDA model\n",
        "    return dictionary,doc_term_matrix"
      ],
      "metadata": {
        "id": "_m5JU1Iv8nMj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gensim_lsa_model(doc_clean,number_of_topics,words):\n",
        "    \"\"\"\n",
        "    Input  : clean document, number of topics and number of words associated with each topic\n",
        "    Purpose: create LSA model using gensim\n",
        "    Output : return LSA model\n",
        "    \"\"\"\n",
        "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
        "    # generate LSA model\n",
        "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
        "    print(lsamodel.print_topics(num_topics=number_of_topics, num_words=words))\n",
        "    return lsamodel"
      ],
      "metadata": {
        "id": "ddVDZyWA8r2B"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSA Model\n",
        "number_of_topics=14\n",
        "words=10\n",
        "#document_list,titles=load_data(\"\",\"articles.txt\")\n",
        "#clean_text=preprocess_data(document_list)\n",
        "model=create_gensim_lsa_model(data_lemmatized,number_of_topics,words)\n",
        "pprint(model.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCDzhQC88xRC",
        "outputId": "3023e125-8eb4-41d3-e39a-1c7eeb7479eb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.426*\"world\" + 0.257*\"make\" + 0.249*\"work\" + 0.215*\"help\" + 0.184*\"year\" + 0.178*\"need\" + 0.177*\"people\" + 0.158*\"health\" + 0.137*\"country\" + 0.132*\"pandemic\"'), (1, '0.597*\"world\" + -0.564*\"year\" + -0.163*\"book\" + 0.122*\"climate_change\" + -0.119*\"country\" + -0.116*\"new\" + -0.108*\"life\" + -0.103*\"lot\" + 0.099*\"need\" + -0.099*\"read\"'), (2, '-0.381*\"health\" + -0.263*\"country\" + 0.261*\"energy\" + 0.225*\"climate_change\" + -0.220*\"help\" + 0.212*\"new\" + 0.210*\"make\" + -0.186*\"covid\" + 0.181*\"year\" + -0.176*\"life\"'), (3, '-0.472*\"world\" + -0.352*\"year\" + 0.332*\"need\" + 0.233*\"help\" + 0.227*\"energy\" + -0.211*\"work\" + 0.169*\"new\" + 0.149*\"innovation\" + 0.146*\"country\" + 0.129*\"pandemic\"'), (4, '0.624*\"work\" + -0.334*\"help\" + -0.245*\"people\" + 0.217*\"health\" + -0.196*\"world\" + -0.170*\"book\" + 0.157*\"energy\" + -0.120*\"disease\" + 0.118*\"thank\" + -0.117*\"new\"'), (5, '-0.609*\"make\" + 0.326*\"work\" + 0.278*\"people\" + -0.224*\"progress\" + 0.209*\"life\" + -0.177*\"health\" + -0.171*\"pandemic\" + 0.158*\"climate_change\" + 0.156*\"book\" + 0.155*\"help\"'), (6, '0.476*\"pandemic\" + -0.348*\"people\" + -0.345*\"make\" + -0.247*\"country\" + 0.246*\"year\" + 0.211*\"covid\" + 0.195*\"need\" + 0.183*\"next\" + -0.175*\"life\" + 0.147*\"end\"'), (7, '0.437*\"help\" + -0.369*\"people\" + -0.247*\"vaccine\" + 0.234*\"health\" + -0.219*\"pandemic\" + -0.216*\"country\" + -0.214*\"get\" + 0.193*\"new\" + -0.175*\"need\" + 0.147*\"energy\"'), (8, '-0.478*\"health\" + 0.355*\"work\" + 0.284*\"make\" + 0.269*\"help\" + -0.242*\"year\" + 0.191*\"pandemic\" + -0.182*\"country\" + -0.142*\"innovation\" + -0.139*\"global\" + 0.130*\"disease\"'), (9, '-0.377*\"book\" + 0.339*\"people\" + -0.312*\"new\" + 0.310*\"help\" + 0.282*\"year\" + 0.214*\"energy\" + -0.180*\"life\" + -0.162*\"read\" + -0.162*\"health\" + 0.144*\"climate_change\"'), (10, '0.413*\"fight\" + 0.411*\"disease\" + -0.245*\"book\" + 0.198*\"polio\" + 0.194*\"alzheimer\" + -0.190*\"help\" + 0.180*\"need\" + 0.169*\"progress\" + 0.161*\"year\" + 0.147*\"climate_change\"'), (11, '-0.337*\"people\" + -0.317*\"new\" + 0.296*\"country\" + 0.285*\"help\" + 0.251*\"get\" + -0.231*\"pandemic\" + 0.161*\"thank\" + -0.161*\"progress\" + -0.157*\"energy\" + 0.154*\"vaccine\"'), (12, '-0.447*\"need\" + 0.315*\"new\" + 0.297*\"country\" + 0.217*\"vaccine\" + 0.193*\"thank\" + 0.188*\"energy\" + -0.184*\"make\" + -0.174*\"help\" + -0.173*\"health\" + -0.167*\"climate_change\"'), (13, '-0.377*\"life\" + 0.359*\"thank\" + 0.214*\"people\" + -0.200*\"world\" + -0.194*\"year\" + -0.193*\"save\" + 0.187*\"progress\" + -0.185*\"need\" + -0.175*\"energy\" + 0.169*\"great\"')]\n",
            "[(0,\n",
            "  '0.426*\"world\" + 0.257*\"make\" + 0.249*\"work\" + 0.215*\"help\" + 0.184*\"year\" + '\n",
            "  '0.178*\"need\" + 0.177*\"people\" + 0.158*\"health\" + 0.137*\"country\" + '\n",
            "  '0.132*\"pandemic\"'),\n",
            " (1,\n",
            "  '0.597*\"world\" + -0.564*\"year\" + -0.163*\"book\" + 0.122*\"climate_change\" + '\n",
            "  '-0.119*\"country\" + -0.116*\"new\" + -0.108*\"life\" + -0.103*\"lot\" + '\n",
            "  '0.099*\"need\" + -0.099*\"read\"'),\n",
            " (2,\n",
            "  '-0.381*\"health\" + -0.263*\"country\" + 0.261*\"energy\" + '\n",
            "  '0.225*\"climate_change\" + -0.220*\"help\" + 0.212*\"new\" + 0.210*\"make\" + '\n",
            "  '-0.186*\"covid\" + 0.181*\"year\" + -0.176*\"life\"'),\n",
            " (3,\n",
            "  '-0.472*\"world\" + -0.352*\"year\" + 0.332*\"need\" + 0.233*\"help\" + '\n",
            "  '0.227*\"energy\" + -0.211*\"work\" + 0.169*\"new\" + 0.149*\"innovation\" + '\n",
            "  '0.146*\"country\" + 0.129*\"pandemic\"'),\n",
            " (4,\n",
            "  '0.624*\"work\" + -0.334*\"help\" + -0.245*\"people\" + 0.217*\"health\" + '\n",
            "  '-0.196*\"world\" + -0.170*\"book\" + 0.157*\"energy\" + -0.120*\"disease\" + '\n",
            "  '0.118*\"thank\" + -0.117*\"new\"'),\n",
            " (5,\n",
            "  '-0.609*\"make\" + 0.326*\"work\" + 0.278*\"people\" + -0.224*\"progress\" + '\n",
            "  '0.209*\"life\" + -0.177*\"health\" + -0.171*\"pandemic\" + 0.158*\"climate_change\" '\n",
            "  '+ 0.156*\"book\" + 0.155*\"help\"'),\n",
            " (6,\n",
            "  '0.476*\"pandemic\" + -0.348*\"people\" + -0.345*\"make\" + -0.247*\"country\" + '\n",
            "  '0.246*\"year\" + 0.211*\"covid\" + 0.195*\"need\" + 0.183*\"next\" + -0.175*\"life\" '\n",
            "  '+ 0.147*\"end\"'),\n",
            " (7,\n",
            "  '0.437*\"help\" + -0.369*\"people\" + -0.247*\"vaccine\" + 0.234*\"health\" + '\n",
            "  '-0.219*\"pandemic\" + -0.216*\"country\" + -0.214*\"get\" + 0.193*\"new\" + '\n",
            "  '-0.175*\"need\" + 0.147*\"energy\"'),\n",
            " (8,\n",
            "  '-0.478*\"health\" + 0.355*\"work\" + 0.284*\"make\" + 0.269*\"help\" + '\n",
            "  '-0.242*\"year\" + 0.191*\"pandemic\" + -0.182*\"country\" + -0.142*\"innovation\" + '\n",
            "  '-0.139*\"global\" + 0.130*\"disease\"'),\n",
            " (9,\n",
            "  '-0.377*\"book\" + 0.339*\"people\" + -0.312*\"new\" + 0.310*\"help\" + 0.282*\"year\" '\n",
            "  '+ 0.214*\"energy\" + -0.180*\"life\" + -0.162*\"read\" + -0.162*\"health\" + '\n",
            "  '0.144*\"climate_change\"'),\n",
            " (10,\n",
            "  '0.413*\"fight\" + 0.411*\"disease\" + -0.245*\"book\" + 0.198*\"polio\" + '\n",
            "  '0.194*\"alzheimer\" + -0.190*\"help\" + 0.180*\"need\" + 0.169*\"progress\" + '\n",
            "  '0.161*\"year\" + 0.147*\"climate_change\"'),\n",
            " (11,\n",
            "  '-0.337*\"people\" + -0.317*\"new\" + 0.296*\"country\" + 0.285*\"help\" + '\n",
            "  '0.251*\"get\" + -0.231*\"pandemic\" + 0.161*\"thank\" + -0.161*\"progress\" + '\n",
            "  '-0.157*\"energy\" + 0.154*\"vaccine\"'),\n",
            " (12,\n",
            "  '-0.447*\"need\" + 0.315*\"new\" + 0.297*\"country\" + 0.217*\"vaccine\" + '\n",
            "  '0.193*\"thank\" + 0.188*\"energy\" + -0.184*\"make\" + -0.174*\"help\" + '\n",
            "  '-0.173*\"health\" + -0.167*\"climate_change\"'),\n",
            " (13,\n",
            "  '-0.377*\"life\" + 0.359*\"thank\" + 0.214*\"people\" + -0.200*\"world\" + '\n",
            "  '-0.194*\"year\" + -0.193*\"save\" + 0.187*\"progress\" + -0.185*\"need\" + '\n",
            "  '-0.175*\"energy\" + 0.169*\"great\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Pgkya2ZAAC"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bPyCVyRGZAAC"
      },
      "outputs": [],
      "source": [
        "# pip install git+https://github.com/bmabey/pyLDAvis.git@master#egg=pyLDAvis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "Ub6ouXu29Qqw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npz = np.load(open('topics.pyldavis.npz', 'r'))\n",
        "dat = {k: v for (k, v) in npz.iteritems()}\n",
        "dat['vocab'] = dat['vocab'].tolist()\n",
        "# dat['term_frequency'] = dat['term_frequency'] * 1.0 / dat['term_frequency'].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "26-rUyBs9Vlp",
        "outputId": "39b8d6e5-f44b-44b8-f81d-fd9d07d50cc0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-98c283bf9eea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'topics.pyldavis.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocab'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dat['term_frequency'] = dat['term_frequency'] * 1.0 / dat['term_frequency'].sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'topics.pyldavis.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAQjuUsaZAAC"
      },
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PnbTucuVZAAD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Write your code here\n",
        "\n",
        "%%capture\n",
        "!pip install bertopic\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"Tweets.csv\")\n",
        "import re\n",
        "\n",
        "def cleantext(tweets):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', tweets) #removes @mentions\n",
        "    text = re.sub(r'#[A-Za-z0-9_]+', '', text) #removing Hashtag symbols.\n",
        "    text = re.sub(r'RT[\\s]+', '', text) #removing Retweet symbol (RT).\n",
        "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #remove URL's.\n",
        "    text = re.sub(r\"www.\\S+\", \"\", text)\n",
        "    text = re.sub('[()!?]', ' ', text)\n",
        "    text = re.sub('\\[.*?\\]',' ', text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]\",\" \", text)#Filtering non-alphanumeric characters\n",
        "    text = re.sub('\\\\n', '', text)#removing the '\\n' character\n",
        "    text = re.sub(r'[0-9]+', '', text)#removing numbers\n",
        "\n",
        "    return text\n",
        "\n",
        "data[\"Text\"] = data[\"Text\"].apply(cleantext)\n",
        "\n",
        "#Converting the text into lower case\n",
        "data['Text']=data[\"Text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "#removing stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "data['Text']=data['Text'].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "\n",
        "#Lemmatization\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "#data['Text']=data['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "# Convert to list\n",
        "docs = data.Text.values.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUDcphEE-i0Z",
        "outputId": "54bdaf54-cbc6-4ab9-9e54-9cded23d85c3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
        "topics, probs = topic_model.fit_transform(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_TWMsGG5-lAN",
        "outputId": "c0293350-5007-4f27-a910-a7188c7ad33f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-bf7525959797>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtopic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_probabilities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.15.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msklearn_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplefilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mumap_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtril\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tril\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriu\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_triu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Re-export vectorize decorators and the thread layer querying function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\n\u001b[0m\u001b[1;32m     43\u001b[0m                             \u001b[0mget_num_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_num_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                             \u001b[0mset_parallel_chunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_parallel_chunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGUVectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyUFunc_None\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyUFunc_Zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyUFunc_One\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_exprs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelUFuncBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelGUFuncBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: initialization of _internal failed without raising an exception"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq = topic_model.get_topic_info(); freq.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "UfBtf1sH-ob3",
        "outputId": "f3a92c59-49c2-4bf0-af6f-a646d66757f6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6b220cb00d9a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topic_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(0)  # Select the most frequent topic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "RYhifQvu-7ac",
        "outputId": "b028987d-faf7-4e9e-e225-b723f802a864"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9250a81ffb1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Select the most frequent topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_topics()\n",
        "topic_model.visualize_distribution(probs[200], min_probability=0.015)\n",
        "topic_model.visualize_hierarchy(top_n_topics=50)\n",
        "topic_model.visualize_barchart(top_n_topics=5)\n",
        "#topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)\n",
        "topic_model.visualize_term_rank()\n",
        "#topic_model.update_topics(docs, topics, n_gram_range=(1, 2))\n",
        "topic_model.get_topic(0)   # We select topic that we viewed before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "unkS7SrV-9gF",
        "outputId": "4e46ad01-867f-4460-867f-9a878d6acef9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-afb48e927d58>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_n_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_barchart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_n_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new_topics, new_probs = topic_model.reduce_topics(docs, topics, probs, nr_topics=20)"
      ],
      "metadata": {
        "id": "EBrIwhhp_IYW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_topics, similarity = topic_model.find_topics(\"energy\", top_n=5); similar_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "t5etAFy0_Req",
        "outputId": "9abc9afe-96aa-4207-f4b8-92a333953f9a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8894a90f03a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilar_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msimilar_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "SfmSgK2k_bmG",
        "outputId": "0399a5dd-175e-473b-fb89-3522f740b1eb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ed8454cd914b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn4q1o34ZAAD"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the analysis provided, it is evident that Latent Dirichlet Allocation (LDA) stands out as the most effective topic modeling method with a topic size of 30. LDA, a well-established technique, excels in extracting themes from textual data, enabling the unsupervised learning of topic clusters from unlabelled documents. However, the challenge lies in ensuring that the extracted topics are coherent and interpretable.\n",
        "\n",
        "To evaluate the quality of LDA topics, the concept of topic coherence is employed. By generating multiple LDA models with varying numbers of topics (k), you can observe a pattern where the coherence score decreases as the number of topics increases. The key is to find a balance where the coherence score remains strong while avoiding topics with repetitive keywords. In this particular analysis, an LDA model with a coherence score of approximately 0.58 was achieved.\n",
        "\n",
        "On the other hand, Latent Semantic Analysis (LSA) also offers valuable insights, but it produces less coherent topics with a coherence score of 0.25. LSA relies on the Bag of Words (BoW) model and singular value decomposition to identify latent themes. It utilizes pairwise word similarity scores to calculate coherence, and as the number of topics increases, the coherence score typically decreases.\n",
        "\n",
        "BerTopic, a more recent topic modeling method, leverages transformers (BERT embeddings) and class-based TF-IDF to generate dense clusters of topics. While it is a promising approach, it is essential to evaluate and compare its performance against established methods like LDA.\n",
        "\n",
        "In conclusion, LDA with a topic size of 30 appears to be the most effective choice, but it is worthwhile to explore BerTopic, given its advanced features and robust vocabulary. The choice between these methods should ultimately align with the specific requirements and objectives of the topic modeling task at hand."
      ],
      "metadata": {
        "id": "Vj_JBiUwAMB3"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}